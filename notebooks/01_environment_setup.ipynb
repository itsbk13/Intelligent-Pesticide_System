{"cells":[{"cell_type":"code","source":["import os\n","from pathlib import Path\n","import builtins\n","import json\n","import pandas as pd\n","import shutil\n","\n","# 1. Mount Google Drive (if not already)\n","from google.colab import drive\n","if not os.path.exists('/content/drive'):\n","    print(\"Mounting Google Drive...\")\n","    drive.mount('/content/drive')\n","    print(\"Google Drive mounted!\")\n","else:\n","    print(\"Google Drive already mounted.\")\n","\n","# 2. Define base project directory on Drive (change if needed)\n","BASE_DIR = Path(\"/content/drive/MyDrive/intelligent_pesticide_system\")\n","\n","# 3. Change working directory to project root (optional)\n","os.chdir(str(BASE_DIR))\n","print(f\"Working directory set to project root: {os.getcwd()}\")\n","\n","# 4. Patch built-in open() to redirect file paths under BASE_DIR automatically,\n","#    unless absolute path already points to BASE_DIR or special paths.\n","\n","original_open = builtins.open\n","\n","def patched_open(file, mode='r', buffering=-1, encoding=None,\n","                 errors=None, newline=None, closefd=True, opener=None):\n","    fpath = file\n","    if isinstance(file, str):\n","        if not (file.startswith(str(BASE_DIR)) or os.path.isabs(file)):\n","            # Redirect relative paths inside BASE_DIR\n","            fpath = BASE_DIR / file\n","    elif isinstance(file, Path):\n","        if not file.is_absolute():\n","            fpath = BASE_DIR / file\n","        else:\n","            fpath = file\n","    else:\n","        fpath = file  # If not str or Path, keep as is\n","\n","    # Ensure parent directories exist for writing\n","    if 'w' in mode or 'a' in mode or 'x' in mode:\n","        os.makedirs(Path(fpath).parent, exist_ok=True)\n","\n","    return original_open(fpath, mode, buffering, encoding, errors, newline, closefd, opener)\n","\n","builtins.open = patched_open\n","\n","# 5. Patch pandas read_csv and to_csv similarly\n","\n","original_read_csv = pd.read_csv\n","def patched_read_csv(filepath_or_buffer, *args, **kwargs):\n","    if isinstance(filepath_or_buffer, str):\n","        if not filepath_or_buffer.startswith(str(BASE_DIR)):\n","            filepath_or_buffer = str(BASE_DIR / filepath_or_buffer)\n","    return original_read_csv(filepath_or_buffer, *args, **kwargs)\n","pd.read_csv = patched_read_csv\n","\n","original_to_csv = pd.DataFrame.to_csv\n","def patched_to_csv(self, path_or_buf=None, *args, **kwargs):\n","    if isinstance(path_or_buf, str) and not path_or_buf.startswith(str(BASE_DIR)):\n","        path_or_buf = str(BASE_DIR / path_or_buf)\n","    os.makedirs(Path(path_or_buf).parent, exist_ok=True)\n","    return original_to_csv(self, path_or_buf, *args, **kwargs)\n","pd.DataFrame.to_csv = patched_to_csv\n","\n","# 6. Patch torch.save similarly if using PyTorch\n","\n","try:\n","    import torch\n","\n","    original_torch_save = torch.save\n","\n","    def patched_torch_save(obj, f, *args, **kwargs):\n","        if isinstance(f, str):\n","            if not f.startswith(str(BASE_DIR)):\n","                f = str(BASE_DIR / f)\n","            os.makedirs(Path(f).parent, exist_ok=True)\n","        return original_torch_save(obj, f, *args, **kwargs)\n","\n","    torch.save = patched_torch_save\n","except ImportError:\n","    print(\"PyTorch not installed, skipping torch.save patch\")\n","\n","# 7. Patch matplotlib.pyplot.savefig to save inside the project folder automatically\n","\n","import matplotlib.pyplot as plt\n","original_savefig = plt.savefig\n","\n","def patched_savefig(fname, *args, **kwargs):\n","    if isinstance(fname, str):\n","        if not fname.startswith(str(BASE_DIR)):\n","            fname = str(BASE_DIR / fname)\n","        os.makedirs(Path(fname).parent, exist_ok=True)\n","    return original_savefig(fname, *args, **kwargs)\n","\n","plt.savefig = patched_savefig\n","\n","print(\"Universal drive path redirection is active. All file reads/writes go to your Drive folder!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yIX_FpRr4MXM","executionInfo":{"status":"ok","timestamp":1759669096234,"user_tz":-330,"elapsed":31335,"user":{"displayName":"Barath Kumar","userId":"05154794485954087994"}},"outputId":"812caf60-2270-42ef-e957-b815fa9fb275"},"id":"yIX_FpRr4MXM","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounting Google Drive...\n","Mounted at /content/drive\n","Google Drive mounted!\n","Working directory set to project root: /content/drive/MyDrive/intelligent_pesticide_system\n","Universal drive path redirection is active. All file reads/writes go to your Drive folder!\n"]}]},{"cell_type":"code","execution_count":null,"id":"7f9e5796-0d7a-4012-ab5f-a42da0927ffc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7f9e5796-0d7a-4012-ab5f-a42da0927ffc","executionInfo":{"status":"ok","timestamp":1759425541664,"user_tz":-330,"elapsed":19,"user":{"displayName":"Barath Kumar","userId":"05154794485954087994"}},"outputId":"00a097e4-c510-485b-de41-5527aed59be2"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ” SYSTEM INFORMATION:\n","==================================================\n","Python Version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n","Platform: Linux-6.6.97+-x86_64-with-glibc2.35\n","Architecture: ('64bit', 'ELF')\n","\n","ğŸ–¥ï¸  GPU INFORMATION:\n","==================================================\n","âœ… CUDA Available: True\n","CUDA Version: 12.6\n","GPU Device: Tesla T4\n","GPU Memory: 14 GB\n","Current GPU: 0\n"]}],"source":["import sys\n","import torch\n","import platform\n","import subprocess\n","import pkg_resources\n","import warnings # Import warnings\n","\n","print(\"ğŸ” SYSTEM INFORMATION:\")\n","print(\"=\" * 50)\n","print(f\"Python Version: {sys.version}\")\n","print(f\"Platform: {platform.platform()}\")\n","print(f\"Architecture: {platform.architecture()}\")\n","\n","# GPU Information\n","print(f\"\\nğŸ–¥ï¸  GPU INFORMATION:\")\n","print(\"=\" * 50)\n","if torch.cuda.is_available():\n","    print(f\"âœ… CUDA Available: {torch.cuda.is_available()}\")\n","    print(f\"CUDA Version: {torch.version.cuda}\")\n","    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n","    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n","    print(f\"Current GPU: {torch.cuda.current_device()}\")\n","else:\n","    print(\"âŒ CUDA not available - using CPU\")\n","    print(\"âš ï¸  Training will be slower on CPU\")\n","\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"id":"6ccd0d00-84dd-44b6-9f84-bac2bc116889","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ccd0d00-84dd-44b6-9f84-bac2bc116889","executionInfo":{"status":"ok","timestamp":1759425461778,"user_tz":-330,"elapsed":49828,"user":{"displayName":"Barath Kumar","userId":"05154794485954087994"}},"outputId":"ce536b48-3925-41fa-d1db-b57cd0ebc2dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“¦ INSTALLING DEPENDENCIES:\n","==================================================\n","Installing torch>=2.0.0...\n","âœ… torch>=2.0.0 installed successfully\n","Installing torchvision>=0.15.0...\n","âœ… torchvision>=0.15.0 installed successfully\n","Installing albumentations>=1.3.0...\n","âœ… albumentations>=1.3.0 installed successfully\n","Installing segmentation-models-pytorch>=0.3.0...\n","âœ… segmentation-models-pytorch>=0.3.0 installed successfully\n","Installing timm>=0.9.0...\n","âœ… timm>=0.9.0 installed successfully\n","Installing opencv-python>=4.8.0...\n","âœ… opencv-python>=4.8.0 installed successfully\n","Installing scikit-learn>=1.3.0...\n","âœ… scikit-learn>=1.3.0 installed successfully\n","Installing matplotlib>=3.7.0...\n","âœ… matplotlib>=3.7.0 installed successfully\n","Installing seaborn>=0.12.0...\n","âœ… seaborn>=0.12.0 installed successfully\n","Installing tqdm>=4.65.0...\n","âœ… tqdm>=4.65.0 installed successfully\n","Installing tensorboard>=2.13.0...\n","âœ… tensorboard>=2.13.0 installed successfully\n","\n","ğŸ‰ Installation complete!\n"]}],"source":["# Install main packages\n","packages_to_install = [\n","    \"torch>=2.0.0\",\n","    \"torchvision>=0.15.0\",\n","    \"albumentations>=1.3.0\",\n","    \"segmentation-models-pytorch>=0.3.0\",\n","    \"timm>=0.9.0\",\n","    \"opencv-python>=4.8.0\",\n","    \"scikit-learn>=1.3.0\",\n","    \"matplotlib>=3.7.0\",\n","    \"seaborn>=0.12.0\",\n","    \"tqdm>=4.65.0\",\n","    \"tensorboard>=2.13.0\"\n","]\n","\n","print(\"ğŸ“¦ INSTALLING DEPENDENCIES:\")\n","print(\"=\" * 50)\n","\n","for package in packages_to_install:\n","    try:\n","        print(f\"Installing {package}...\")\n","        !pip install {package} --quiet\n","        print(f\"âœ… {package} installed successfully\")\n","    except Exception as e:\n","        print(f\"âŒ Error installing {package}: {e}\")\n","\n","print(\"\\nğŸ‰ Installation complete!\")\n"]},{"cell_type":"code","execution_count":null,"id":"2aedc15a-e481-404c-bc3f-9d992e587a3a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2aedc15a-e481-404c-bc3f-9d992e587a3a","executionInfo":{"status":"ok","timestamp":1759425563200,"user_tz":-330,"elapsed":12102,"user":{"displayName":"Barath Kumar","userId":"05154794485954087994"}},"outputId":"978f9a2c-06f0-4587-c187-88279b5a241e"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“š LIBRARY VERSIONS\n","==================================================\n","torch: 2.8.0+cu126\n","torchvision: 2.8.0+cu126\n","numpy: 2.0.2\n","pandas: 2.2.2\n","opencv: 4.12.0\n","matplotlib: 3.10.0\n","\n","âœ… All libraries imported successfully!\n"]}],"source":["# Core libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","\n","# Computer Vision & Augmentation\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import segmentation_models_pytorch as smp\n","import timm\n","import cv2\n","\n","# Data Science\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","\n","# Utilities\n","import os\n","import json\n","from pathlib import Path\n","from tqdm import tqdm\n","import warnings\n","import time\n","from collections import defaultdict\n","\n","warnings.filterwarnings('ignore')\n","\n","print(\"ğŸ“š LIBRARY VERSIONS\")\n","print(\"=\" * 50)\n","libraries = {\n","    'torch': torch.__version__,\n","    'torchvision': torch.version.__version__ if hasattr(torch.version, '__version__') else 'N/A',\n","    'numpy': np.__version__,\n","    'pandas': pd.__version__,\n","    'opencv': cv2.__version__,\n","    'matplotlib': plt.matplotlib.__version__ if hasattr(plt, 'matplotlib') else 'N/A',\n","}\n","\n","for lib, version in libraries.items():\n","    print(f\"{lib}: {version}\")\n","\n","print(\"\\nâœ… All libraries imported successfully!\")\n"]},{"cell_type":"code","execution_count":null,"id":"97a73b67-85bb-4bb1-b0a5-36064ac5f517","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97a73b67-85bb-4bb1-b0a5-36064ac5f517","executionInfo":{"status":"ok","timestamp":1759425567959,"user_tz":-330,"elapsed":2991,"user":{"displayName":"Barath Kumar","userId":"05154794485954087994"}},"outputId":"7f54376c-4728-4b5e-873a-c0be7cecbe0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“ Creating project directory structure...\n","âœ… Directory structure created successfully!\n","âš™ï¸  PROJECT CONFIGURATION\n","============================================================\n","Project Root: /content/drive/MyDrive/intelligent_pesticide_system\n","Notebooks Dir: /content/drive/MyDrive/intelligent_pesticide_system/notebooks\n","Data Directory: /content/drive/MyDrive/intelligent_pesticide_system/data\n","Models Directory: /content/drive/MyDrive/intelligent_pesticide_system/models\n","Results Directory: /content/drive/MyDrive/intelligent_pesticide_system/results\n","Device: cuda\n","Image Size: 512\n","Batch Size: 8\n","Learning Rate: 0.0001\n","Num Epochs: 50\n","Num Classes: 4\n","Severity Labels: {0: 'healthy', 1: 'curl', 2: 'spot', 3: 'slug'}\n","Spray Thresholds: Low=15.0%, High=30.0%\n","Data Splits: Train=0.7, Val=0.2, Test=0.1\n","ğŸ’¾ Configuration saved to: /content/drive/MyDrive/intelligent_pesticide_system/configs/runtime_config.json\n"]},{"output_type":"execute_result","data":{"text/plain":["PosixPath('/content/drive/MyDrive/intelligent_pesticide_system/configs/runtime_config.json')"]},"metadata":{},"execution_count":10}],"source":["import os\n","import json\n","from pathlib import Path\n","\n","class ProjectConfig:\n","    def __init__(self):\n","        current_dir = Path.cwd()\n","\n","        if current_dir.name == 'notebooks':\n","            self.BASE_DIR = current_dir.parent\n","            self.NOTEBOOKS_DIR = current_dir\n","        else:\n","            self.BASE_DIR = current_dir\n","            self.NOTEBOOKS_DIR = self.BASE_DIR / 'notebooks'\n","\n","        # All main directories should be at project root level\n","        self.DATA_DIR = self.BASE_DIR / \"data\"\n","        self.RAW_DATA_DIR = self.DATA_DIR / \"raw\"\n","        self.PROCESSED_DATA_DIR = self.DATA_DIR / \"processed\"\n","        self.MODELS_DIR = self.BASE_DIR / \"models\"\n","        self.RESULTS_DIR = self.BASE_DIR / \"results\"\n","        self.SRC_DIR = self.BASE_DIR / \"src\"\n","        self.CONFIGS_DIR = self.BASE_DIR / \"configs\"\n","\n","        # Device setup\n","        try:\n","            import torch\n","            self.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        except ImportError:\n","            self.DEVICE = 'cpu'\n","\n","        # Model parameters\n","        self.IMAGE_SIZE = 512\n","        self.BATCH_SIZE = 8\n","        self.NUM_WORKERS = 4\n","\n","        # Training parameters\n","        self.LEARNING_RATE = 1e-4\n","        self.NUM_EPOCHS = 50\n","        self.EARLY_STOPPING_PATIENCE = 10\n","\n","        # Dataset parameters\n","        self.NUM_CLASSES = 4\n","        self.SEVERITY_LABELS = {0: 'healthy', 1: 'curl', 2: 'spot', 3: 'slug'}  # Updated based on DiaMOS\n","\n","        # Spray decision thresholds\n","        self.LOW_SPRAY_THRESHOLD = 15.0\n","        self.HIGH_SPRAY_THRESHOLD = 30.0\n","\n","        # Data split ratios\n","        self.TRAIN_RATIO = 0.7\n","        self.VAL_RATIO = 0.2\n","        self.TEST_RATIO = 0.1\n","\n","    def create_directories(self):\n","        \"\"\"Create necessary directories based on actual dataset structures\"\"\"\n","        directories = [\n","            # Core directories\n","            self.DATA_DIR,\n","            self.RAW_DATA_DIR,\n","            self.PROCESSED_DATA_DIR,\n","            self.MODELS_DIR,\n","            self.RESULTS_DIR,\n","            self.SRC_DIR,\n","            self.CONFIGS_DIR,\n","\n","\n","            self.RAW_DATA_DIR / \"plantseg\",\n","\n","            self.RAW_DATA_DIR / \"diamos\",\n","\n","            # Processed data directories\n","            self.PROCESSED_DATA_DIR / \"segmentation\" / \"train\",\n","            self.PROCESSED_DATA_DIR / \"segmentation\" / \"val\",\n","            self.PROCESSED_DATA_DIR / \"segmentation\" / \"test\",\n","            self.PROCESSED_DATA_DIR / \"classification\" / \"train\",\n","            self.PROCESSED_DATA_DIR / \"classification\" / \"val\",\n","            self.PROCESSED_DATA_DIR / \"classification\" / \"test\",\n","\n","            # Model directories\n","            self.MODELS_DIR / \"checkpoints\",\n","            self.MODELS_DIR / \"architectures\",\n","            self.MODELS_DIR / \"pretrained\",\n","\n","            # Results directories\n","            self.RESULTS_DIR / \"logs\" / \"tensorboard\",\n","            self.RESULTS_DIR / \"logs\" / \"training\",\n","            self.RESULTS_DIR / \"visualizations\" / \"training_curves\",\n","            self.RESULTS_DIR / \"visualizations\" / \"predictions\",\n","            self.RESULTS_DIR / \"metrics\",\n","            self.RESULTS_DIR / \"reports\",\n","\n","            # Source code directories\n","            self.SRC_DIR / \"data\",\n","            self.SRC_DIR / \"models\",\n","            self.SRC_DIR / \"training\",\n","            self.SRC_DIR / \"inference\",\n","            self.SRC_DIR / \"utils\",\n","\n","            # Metadata directory\n","            self.DATA_DIR / \"metadata\",\n","\n","            # Notebooks directory\n","            self.NOTEBOOKS_DIR,\n","\n","            # Additional directories\n","            self.BASE_DIR / \"docs\",\n","            self.BASE_DIR / \"scripts\",\n","            self.BASE_DIR / \"tests\"\n","        ]\n","\n","        print(\"ğŸ“ Creating project directory structure...\")\n","        for directory in directories:\n","            directory.mkdir(parents=True, exist_ok=True)\n","\n","        # Create __init__.py files for Python packages\n","        init_files = [\n","            self.SRC_DIR / \"__init__.py\",\n","            self.SRC_DIR / \"data\" / \"__init__.py\",\n","            self.SRC_DIR / \"models\" / \"__init__.py\",\n","            self.SRC_DIR / \"training\" / \"__init__.py\",\n","            self.SRC_DIR / \"inference\" / \"__init__.py\",\n","            self.SRC_DIR / \"utils\" / \"__init__.py\"\n","        ]\n","\n","        for init_file in init_files:\n","            init_file.touch(exist_ok=True)\n","\n","        print(\"âœ… Directory structure created successfully!\")\n","\n","    def print_config(self):\n","        \"\"\"Print current configuration\"\"\"\n","        print(\"âš™ï¸  PROJECT CONFIGURATION\")\n","        print(\"=\" * 60)\n","        print(f\"Project Root: {self.BASE_DIR}\")\n","        print(f\"Notebooks Dir: {self.NOTEBOOKS_DIR}\")\n","        print(f\"Data Directory: {self.DATA_DIR}\")\n","        print(f\"Models Directory: {self.MODELS_DIR}\")\n","        print(f\"Results Directory: {self.RESULTS_DIR}\")\n","        print(f\"Device: {self.DEVICE}\")\n","        print(f\"Image Size: {self.IMAGE_SIZE}\")\n","        print(f\"Batch Size: {self.BATCH_SIZE}\")\n","        print(f\"Learning Rate: {self.LEARNING_RATE}\")\n","        print(f\"Num Epochs: {self.NUM_EPOCHS}\")\n","        print(f\"Num Classes: {self.NUM_CLASSES}\")\n","        print(f\"Severity Labels: {self.SEVERITY_LABELS}\")\n","        print(f\"Spray Thresholds: Low={self.LOW_SPRAY_THRESHOLD}%, High={self.HIGH_SPRAY_THRESHOLD}%\")\n","        print(f\"Data Splits: Train={self.TRAIN_RATIO}, Val={self.VAL_RATIO}, Test={self.TEST_RATIO}\")\n","\n","    def save_config(self):\n","        \"\"\"Save configuration to JSON file\"\"\"\n","        config_dict = {\n","            'paths': {\n","                'base_dir': str(self.BASE_DIR),\n","                'data_dir': str(self.DATA_DIR),\n","                'raw_data_dir': str(self.RAW_DATA_DIR),\n","                'processed_data_dir': str(self.PROCESSED_DATA_DIR),\n","                'models_dir': str(self.MODELS_DIR),\n","                'results_dir': str(self.RESULTS_DIR),\n","                'notebooks_dir': str(self.NOTEBOOKS_DIR),\n","                'metadata_dir': str(self.DATA_DIR / \"metadata\")\n","            },\n","            'device': str(self.DEVICE),\n","            'model_params': {\n","                'image_size': self.IMAGE_SIZE,\n","                'batch_size': self.BATCH_SIZE,\n","                'num_workers': self.NUM_WORKERS\n","            },\n","            'training_params': {\n","                'learning_rate': self.LEARNING_RATE,\n","                'num_epochs': self.NUM_EPOCHS,\n","                'early_stopping_patience': self.EARLY_STOPPING_PATIENCE\n","            },\n","            'dataset_params': {\n","                'num_classes': self.NUM_CLASSES,\n","                'severity_labels': self.SEVERITY_LABELS,\n","                'spray_thresholds': {\n","                    'low': self.LOW_SPRAY_THRESHOLD,\n","                    'high': self.HIGH_SPRAY_THRESHOLD\n","                },\n","                'data_splits': {\n","                    'train': self.TRAIN_RATIO,\n","                    'val': self.VAL_RATIO,\n","                    'test': self.TEST_RATIO\n","                }\n","            },\n","            'dataset_info': {\n","                'plantseg': {\n","                    'type': 'segmentation',\n","                    'has_pretrained_splits': True,\n","                    'structure': 'images/{train,val,test}/, annotations/{train,val,test}/, json/'\n","                },\n","                'diamos': {\n","                    'type': 'classification',\n","                    'categories': ['healthy', 'curl', 'spot', 'slug'],\n","                    'structure': 'leaves/{healthy,curl,spot,slug}/, fruits/, annotation/csv/'\n","                }\n","            }\n","        }\n","\n","        config_file = self.CONFIGS_DIR / 'runtime_config.json'\n","        with open(config_file, 'w') as f:\n","            json.dump(config_dict, f, indent=2)\n","\n","        print(f\"ğŸ’¾ Configuration saved to: {config_file}\")\n","        return config_file\n","\n","# Initialize and create configuration\n","config = ProjectConfig()\n","config.create_directories()\n","config.print_config()\n","config.save_config()\n"]},{"cell_type":"code","execution_count":null,"id":"6db522d4-71ce-45bb-b5e2-f89801e2ba9b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6db522d4-71ce-45bb-b5e2-f89801e2ba9b","executionInfo":{"status":"ok","timestamp":1759425602320,"user_tz":-330,"elapsed":1242,"user":{"displayName":"Barath Kumar","userId":"05154794485954087994"}},"outputId":"b6c294e7-0102-4098-f667-c09ac08f24ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ§ª TESTING PYTORCH FUNCTIONALITY\n","==================================================\n","Testing tensor operations...\n","âœ… Created tensor with shape: torch.Size([3, 224, 224])\n","\n","Testing GPU operations...\n","âœ… GPU tensor operations successful\n","Result tensor device: cuda:0\n","\n","GPU Memory Usage:\n","Allocated: 1.7 MB\n","Reserved: 2.0 MB\n","\n","Testing neural network creation...\n","âœ… Test model forward pass successful\n","Input shape: torch.Size([2, 3, 64, 64])\n","Output shape: torch.Size([2, 4])\n","\n","ğŸ‰ All PyTorch functionality tests passed!\n"]}],"source":["print(\"ğŸ§ª TESTING PYTORCH FUNCTIONALITY\")\n","print(\"=\" * 50)\n","\n","# Test tensor operations\n","print(\"Testing tensor operations...\")\n","x = torch.randn(3, 224, 224)\n","print(f\"âœ… Created tensor with shape: {x.shape}\")\n","\n","# Test GPU operations if available\n","if torch.cuda.is_available():\n","    print(\"\\nTesting GPU operations...\")\n","    x_gpu = x.to(config.DEVICE)\n","    y_gpu = torch.randn(3, 224, 224).to(config.DEVICE)\n","    z_gpu = x_gpu + y_gpu\n","    print(f\"âœ… GPU tensor operations successful\")\n","    print(f\"Result tensor device: {z_gpu.device}\")\n","\n","    # Test memory allocation\n","    print(f\"\\nGPU Memory Usage:\")\n","    print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**2:.1f} MB\")\n","    print(f\"Reserved: {torch.cuda.memory_reserved() / 1024**2:.1f} MB\")\n","else:\n","    print(\"âš ï¸  Running on CPU - GPU tests skipped\")\n","\n","# Test a simple neural network\n","print(\"\\nTesting neural network creation...\")\n","test_model = nn.Sequential(\n","    nn.Conv2d(3, 16, 3, padding=1),\n","    nn.ReLU(),\n","    nn.AdaptiveAvgPool2d(1),\n","    nn.Flatten(),\n","    nn.Linear(16, 4)\n",").to(config.DEVICE)\n","\n","# Test forward pass\n","test_input = torch.randn(2, 3, 64, 64).to(config.DEVICE)\n","with torch.no_grad():\n","    test_output = test_model(test_input)\n","\n","print(f\"âœ… Test model forward pass successful\")\n","print(f\"Input shape: {test_input.shape}\")\n","print(f\"Output shape: {test_output.shape}\")\n","\n","# Clean up\n","del test_model, test_input, test_output\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","\n","print(\"\\nğŸ‰ All PyTorch functionality tests passed!\")\n"]},{"cell_type":"code","execution_count":null,"id":"e7c97182-0837-40d4-b8db-8928bc8cb1e1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7c97182-0837-40d4-b8db-8928bc8cb1e1","executionInfo":{"status":"ok","timestamp":1759669113967,"user_tz":-330,"elapsed":5918,"user":{"displayName":"Barath Kumar","userId":"05154794485954087994"}},"outputId":"537bc8f6-b694-4901-e339-a47812a0cab6"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“ CHECKING PROJECT STRUCTURE (UPDATED FOR REAL DATASETS)\n","======================================================================\n","ğŸ” Running from project root\n","ğŸ“‚ Project root: /content/drive/MyDrive/intelligent_pesticide_system\n","----------------------------------------------------------------------\n","âœ… data/\n","   âœ… raw/plantseg/\n","   âœ… raw/diamos/\n","   âœ… processed/segmentation/\n","   âœ… processed/classification/\n","   âœ… metadata/\n","âœ… models/\n","   âœ… checkpoints/\n","   âœ… architectures/\n","   âœ… pretrained/\n","âœ… results/\n","   âœ… logs/\n","   âœ… visualizations/\n","   âœ… metrics/\n","   âœ… reports/\n","âœ… src/\n","   âœ… data/\n","   âœ… models/\n","   âœ… training/\n","   âœ… inference/\n","   âœ… utils/\n","âœ… configs/\n","âœ… notebooks/\n","âœ… docs/\n","âœ… scripts/\n","âœ… tests/\n","\n","ğŸ“Š CHECKING ACTUAL DATASETS:\n","   âœ… plantseg/images/ (3 subdirs)\n","   âœ… plantseg/annotations/ (3 subdirs)\n","   âœ… plantseg/json/ (1 subdirs)\n","   ğŸ‰ PlantSeg structure looks good!\n","   âœ… diamos/leaves/ (4 categories)\n","   âœ… diamos/annotation/csv/ (CSV found)\n","   ğŸ‰ DiaMOS structure looks good!\n","\n","ğŸ‰ Project structure is complete!\n","\n","ğŸ“‚ PROJECT TREE STRUCTURE:\n","==================================================\n","intelligent_pesticide_system/\n","â”œâ”€â”€ .ipynb_checkpoints/\n","â”œâ”€â”€ configs/\n","â”œâ”€â”€ data/\n","â”‚   â”œâ”€â”€ metadata/\n","â”‚   â”œâ”€â”€ processed/\n","â”‚   â”‚   â”œâ”€â”€ classification/ (0 files, 3 dirs)\n","â”‚   â”‚   â””â”€â”€ segmentation/ (0 files, 3 dirs)\n","â”‚   â””â”€â”€ raw/\n","â”‚       â”œâ”€â”€ demo_batch/ (9 files, 0 dirs)\n","â”‚       â”œâ”€â”€ diamos/ (0 files, 3 dirs)\n","â”‚       â””â”€â”€ plantseg/ (1 files, 4 dirs)\n","â”œâ”€â”€ docs/\n","â”œâ”€â”€ models/\n","â”‚   â”œâ”€â”€ architectures/\n","â”‚   â”œâ”€â”€ checkpoints/\n","â”‚   â”œâ”€â”€ nwrd/\n","â”‚   â”‚   â””â”€â”€ NUST-Wheat-Rust-Disease-NWRD/ (9 files, 8 dirs)\n","â”‚   â”œâ”€â”€ pretrained/\n","â”‚   â””â”€â”€ trained/\n","â”‚       â””â”€â”€ .ipynb_checkpoints/\n","â”œâ”€â”€ notebooks/\n","â”‚   â””â”€â”€ .ipynb_checkpoints/\n","â”œâ”€â”€ results/\n","â”‚   â”œâ”€â”€ evaluation/\n","â”‚   â”œâ”€â”€ evaluation_testing/\n","â”‚   â”œâ”€â”€ logs/\n","â”‚   â”‚   â”œâ”€â”€ tensorboard/\n","â”‚   â”‚   â””â”€â”€ training/\n","â”‚   â”œâ”€â”€ metrics/\n","â”‚   â””â”€â”€ notebook_4_architecture/\n","â”‚       â””â”€â”€ .ipynb_checkpoints/ (4 files, 0 dirs)\n","â”‚       ... and 6 more directories\n","â””â”€â”€ scripts/\n","    ... and 2 more directories\n"]}],"source":["from pathlib import Path\n","\n","def check_project_structure():\n","    \"\"\"Verify project structure based on actual dataset formats\"\"\"\n","    print(\"ğŸ“ CHECKING PROJECT STRUCTURE (UPDATED FOR REAL DATASETS)\")\n","    print(\"=\" * 70)\n","\n","    # Determine project root correctly\n","    current_dir = Path.cwd()\n","    if current_dir.name == 'notebooks':\n","        project_root = current_dir.parent\n","        print(f\"ğŸ” Running from notebooks folder\")\n","    else:\n","        project_root = current_dir\n","        print(f\"ğŸ” Running from project root\")\n","\n","    print(f\"ğŸ“‚ Project root: {project_root}\")\n","    print(\"-\" * 70)\n","\n","    # Updated required structure based on actual datasets\n","    required_structure = {\n","        \"data\": [\n","            \"raw/plantseg\",         # PlantSeg will have its own internal structure\n","            \"raw/diamos\",           # DiaMOS will have its own internal structure\n","            \"processed/segmentation\",\n","            \"processed/classification\",\n","            \"metadata\"\n","        ],\n","        \"models\": [\"checkpoints\", \"architectures\", \"pretrained\"],\n","        \"results\": [\"logs\", \"visualizations\", \"metrics\", \"reports\"],\n","        \"src\": [\"data\", \"models\", \"training\", \"inference\", \"utils\"],\n","        \"configs\": [],\n","        \"notebooks\": [],\n","        \"docs\": [],\n","        \"scripts\": [],\n","        \"tests\": []\n","    }\n","\n","    all_exist = True\n","    missing_dirs = []\n","\n","    for main_dir, sub_dirs in required_structure.items():\n","        main_path = project_root / main_dir\n","\n","        if main_path.exists():\n","            print(f\"âœ… {main_dir}/\")\n","\n","            # Check subdirectories\n","            for sub_dir in sub_dirs:\n","                sub_path = main_path / sub_dir\n","                if sub_path.exists():\n","                    print(f\"   âœ… {sub_dir}/\")\n","                else:\n","                    print(f\"   âŒ {sub_dir}/ - MISSING\")\n","                    missing_dirs.append(f\"{main_dir}/{sub_dir}\")\n","                    all_exist = False\n","        else:\n","            print(f\"âŒ {main_dir}/ - MISSING\")\n","            missing_dirs.append(main_dir)\n","            all_exist = False\n","\n","    # Special checks for actual datasets\n","    print(f\"\\nğŸ“Š CHECKING ACTUAL DATASETS:\")\n","\n","    # Check PlantSeg structure\n","    plantseg_path = project_root / \"data\" / \"raw\" / \"plantseg\"\n","    if plantseg_path.exists():\n","        expected_plantseg_dirs = [\"images\", \"annotations\", \"json\"]\n","        plantseg_structure_ok = True\n","\n","        for expected_dir in expected_plantseg_dirs:\n","            dir_path = plantseg_path / expected_dir\n","            if dir_path.exists():\n","                # Count subdirectories (train/val/test)\n","                subdirs = [d for d in dir_path.iterdir() if d.is_dir()]\n","                print(f\"   âœ… plantseg/{expected_dir}/ ({len(subdirs)} subdirs)\")\n","            else:\n","                print(f\"   âŒ plantseg/{expected_dir}/ - MISSING\")\n","                plantseg_structure_ok = False\n","\n","        if plantseg_structure_ok:\n","            print(f\"   ğŸ‰ PlantSeg structure looks good!\")\n","        else:\n","            print(f\"   âš ï¸  PlantSeg structure incomplete\")\n","    else:\n","        print(f\"   âŒ PlantSeg dataset not found at {plantseg_path}\")\n","\n","    # Check DiaMOS structure\n","    diamos_path = project_root / \"data\" / \"raw\" / \"diamos\"\n","    if diamos_path.exists():\n","        expected_diamos_dirs = [\"leaves\", \"annotation\"]\n","        diamos_structure_ok = True\n","\n","        for expected_dir in expected_diamos_dirs:\n","            dir_path = diamos_path / expected_dir\n","            if dir_path.exists():\n","                if expected_dir == \"leaves\":\n","                    # Check for severity categories\n","                    categories = [d for d in dir_path.iterdir() if d.is_dir()]\n","                    print(f\"   âœ… diamos/leaves/ ({len(categories)} categories)\")\n","                elif expected_dir == \"annotation\":\n","                    csv_file = dir_path / \"csv\" / \"diaMOSPlant.csv\"\n","                    if csv_file.exists():\n","                        print(f\"   âœ… diamos/annotation/csv/ (CSV found)\")\n","                    else:\n","                        print(f\"   âš ï¸  diamos/annotation/csv/ (no CSV)\")\n","            else:\n","                print(f\"   âŒ diamos/{expected_dir}/ - MISSING\")\n","                diamos_structure_ok = False\n","\n","        if diamos_structure_ok:\n","            print(f\"   ğŸ‰ DiaMOS structure looks good!\")\n","        else:\n","            print(f\"   âš ï¸  DiaMOS structure incomplete\")\n","    else:\n","        print(f\"   âŒ DiaMOS dataset not found at {diamos_path}\")\n","\n","    # Check for wrongly placed directories\n","    if (project_root / 'notebooks').exists():\n","        notebooks_dir = project_root / 'notebooks'\n","        wrong_locations = []\n","\n","        for dir_name in ['data', 'models', 'results', 'src']:\n","            wrong_path = notebooks_dir / dir_name\n","            if wrong_path.exists():\n","                wrong_locations.append(f\"notebooks/{dir_name}\")\n","\n","        if wrong_locations:\n","            print(f\"\\nâš ï¸  DIRECTORIES IN WRONG LOCATIONS:\")\n","            for wrong_dir in wrong_locations:\n","                print(f\"   ğŸ“ {wrong_dir} (should be at project root)\")\n","\n","    if all_exist:\n","        print(f\"\\nğŸ‰ Project structure is complete!\")\n","    else:\n","        print(f\"\\nâš ï¸  Missing directories: {len(missing_dirs)}\")\n","\n","        # Auto-create missing directories\n","        print(\"Creating missing directories...\")\n","        for main_dir, sub_dirs in required_structure.items():\n","            main_path = project_root / main_dir\n","            main_path.mkdir(exist_ok=True)\n","\n","            for sub_dir in sub_dirs:\n","                sub_path = main_path / sub_dir\n","                sub_path.mkdir(parents=True, exist_ok=True)\n","\n","        print(\"âœ… Missing directories created!\")\n","\n","    return all_exist, project_root\n","\n","# Run the updated check\n","structure_ok, project_root = check_project_structure()\n","\n","# Display the updated project tree\n","def display_project_tree(directory, max_depth=3):\n","    \"\"\"Display project tree structure with more depth for datasets\"\"\"\n","    def _display_tree(path, prefix=\"\", current_depth=0):\n","        if current_depth >= max_depth:\n","            return\n","\n","        items = sorted([item for item in path.iterdir() if item.is_dir()])\n","\n","        # Limit items shown to avoid clutter\n","        display_items = items[:8] if current_depth == 0 else items[:5]\n","\n","        for i, item in enumerate(display_items):\n","            is_last = i == len(display_items) - 1\n","            current_prefix = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n","\n","            # Show file count for leaf directories\n","            if current_depth == max_depth - 1:\n","                try:\n","                    file_count = len([f for f in item.iterdir() if f.is_file()])\n","                    dir_count = len([d for d in item.iterdir() if d.is_dir()])\n","                    info = f\" ({file_count} files, {dir_count} dirs)\" if file_count > 0 or dir_count > 0 else \"\"\n","                except:\n","                    info = \"\"\n","                print(f\"{prefix}{current_prefix}{item.name}/{info}\")\n","            else:\n","                print(f\"{prefix}{current_prefix}{item.name}/\")\n","\n","            if current_depth < max_depth - 1:\n","                extension = \"    \" if is_last else \"â”‚   \"\n","                _display_tree(item, prefix + extension, current_depth + 1)\n","\n","        if len(items) > len(display_items):\n","            remaining = len(items) - len(display_items)\n","            print(f\"{prefix}    ... and {remaining} more directories\")\n","\n","    print(f\"\\nğŸ“‚ PROJECT TREE STRUCTURE:\")\n","    print(\"=\" * 50)\n","    print(f\"{directory.name}/\")\n","    _display_tree(directory)\n","\n","if structure_ok:\n","    display_project_tree(project_root)\n"]},{"cell_type":"code","execution_count":null,"id":"9ecb0ac3-fd63-4022-a154-b4be81d0f0a1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ecb0ac3-fd63-4022-a154-b4be81d0f0a1","executionInfo":{"status":"ok","timestamp":1759425636590,"user_tz":-330,"elapsed":838,"user":{"displayName":"Barath Kumar","userId":"05154794485954087994"}},"outputId":"41424371-f500-4982-d00c-c25679561932"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“‹ ENVIRONMENT SETUP SUMMARY (UPDATED)\n","======================================================================\n","System Status: âœ… Ready\n","Dependencies: âœ… Complete\n","Project Structure: âœ… Complete\n","PlantSeg Dataset: âœ… Found\n","DiaMOS Dataset: âœ… Found\n","\n","ğŸ¯ DATASET INFORMATION:\n","ğŸ“Š PlantSeg: Segmentation dataset with train/val/test splits\n","   - Structure: images/{train,val,test}/ + annotations/{train,val,test}/\n","   - Format: JPG images + PNG masks + JSON annotations\n","ğŸ“Š DiaMOS: Classification dataset with severity levels\n","   - Structure: leaves/{healthy,curl,spot,slug}/ + annotation/csv/\n","   - Format: JPG images + CSV metadata\n","\n","ğŸ¯ DATASET CHECK:\n","âœ… All datasets ready!\n","\n","ğŸ’¾ Setup status saved to: /content/drive/MyDrive/intelligent_pesticide_system/configs/setup_status.json\n","\n","ğŸš€ Environment setup complete!\n"]}],"source":["print(\"ğŸ“‹ ENVIRONMENT SETUP SUMMARY (UPDATED)\")\n","print(\"=\" * 70)\n","\n","# System check\n","try:\n","    import torch\n","    system_status = \"âœ… Ready\" if torch.cuda.is_available() else \"âš ï¸  CPU Only\"\n","except ImportError:\n","    system_status = \"âŒ PyTorch not found\"\n","\n","print(f\"System Status: {system_status}\")\n","\n","# Dependencies check\n","try:\n","    import segmentation_models_pytorch as smp\n","    import timm\n","    import albumentations as A\n","    deps_status = \"âœ… Complete\"\n","except ImportError as e:\n","    deps_status = f\"âŒ Missing: {e}\"\n","\n","print(f\"Dependencies: {deps_status}\")\n","\n","# Project structure check\n","structure_status = \"âœ… Complete\" if structure_ok else \"âŒ Incomplete\"\n","print(f\"Project Structure: {structure_status}\")\n","\n","# Dataset status check\n","plantseg_status = \"âœ… Found\" if (project_root / \"data\" / \"raw\" / \"plantseg\" / \"images\").exists() else \"âŒ Missing\"\n","diamos_status = \"âœ… Found\" if (project_root / \"data\" / \"raw\" / \"diamos\" / \"leaves\").exists() else \"âŒ Missing\"\n","\n","print(f\"PlantSeg Dataset: {plantseg_status}\")\n","print(f\"DiaMOS Dataset: {diamos_status}\")\n","\n","print(f\"\\nğŸ¯ DATASET INFORMATION:\")\n","print(f\"ğŸ“Š PlantSeg: Segmentation dataset with train/val/test splits\")\n","print(f\"   - Structure: images/{{train,val,test}}/ + annotations/{{train,val,test}}/\")  # Fixed: Use curly braces in string\n","print(f\"   - Format: JPG images + PNG masks + JSON annotations\")\n","\n","print(f\"ğŸ“Š DiaMOS: Classification dataset with severity levels\")\n","print(f\"   - Structure: leaves/{{healthy,curl,spot,slug}}/ + annotation/csv/\")  # Fixed: Use curly braces in string\n","print(f\"   - Format: JPG images + CSV metadata\")\n","\n","print(f\"\\nğŸ¯ DATASET CHECK:\")\n","if plantseg_status == \"âŒ Missing\":\n","    print(\"â— Download PlantSeg dataset to data/raw/plantseg/\")\n","if diamos_status == \"âŒ Missing\":\n","    print(\"â— Download DiaMOS dataset to data/raw/diamos/\")\n","\n","if plantseg_status == \"âœ… Found\" and diamos_status == \"âœ… Found\":\n","    print(\"âœ… All datasets ready!\")\n","else:\n","    print(\"1. Download missing datasets\")\n","    print(\"2. Re-run this notebook to verify setup\")\n","\n","# Save final configuration with dataset status\n","final_config = {\n","    'setup_complete': True,\n","    'system_ready': system_status == \"âœ… Ready\",\n","    'dependencies_ready': deps_status == \"âœ… Complete\",\n","    'structure_ready': structure_status == \"âœ… Complete\",\n","    'plantseg_found': plantseg_status == \"âœ… Found\",\n","    'diamos_found': diamos_status == \"âœ… Found\",\n","    'ready_for_data_prep': (plantseg_status == \"âœ… Found\" and diamos_status == \"âœ… Found\")\n","}\n","\n","# Save setup status\n","setup_file = project_root / \"configs\" / \"setup_status.json\"\n","with open(setup_file, 'w') as f:\n","    json.dump(final_config, f, indent=2)\n","\n","print(f\"\\nğŸ’¾ Setup status saved to: {setup_file}\")\n","\n","if final_config['ready_for_data_prep']:\n","    print(f\"\\nğŸš€ Environment setup complete!\")\n","else:\n","    print(f\"\\nâš ï¸  Setup incomplete. Please resolve issues above before proceeding.\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}